{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        \n",
    "        self.base_model = AutoModel.from_pretrained('bert-base-uncased', output_hidden_states = True, output_attentions=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids, attn_mask):\n",
    "        outputs = self.base_model(input_ids, token_type_ids=token_type_ids, attention_mask=attn_mask)\n",
    "        outputs = self.dropout(outputs[1])\n",
    "        outputs = self.linear(outputs)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "model = CustomModel()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def print_layers_and_return_weights(model):\n",
    "    parameters = deepcopy(model.state_dict())\n",
    "    print(\"Model's state_dict:\")\n",
    "    for param_tensor in parameters:\n",
    "        print(param_tensor, \"\\t\", parameters[param_tensor].size())\n",
    "    print()\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def print_output_innerbert(model, text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to('cuda')\n",
    "    output = model(encoded_input['input_ids'], encoded_input['token_type_ids'], encoded_input['attention_mask'])\n",
    "    print(\"Text: \", text)\n",
    "    print(\"Encoded Input Length: \", len(encoded_input['input_ids'][0]))\n",
    "    print(\"Encoded Input: \", encoded_input['input_ids'][0])\n",
    "    print(\"Output Size: \", output[0].shape)\n",
    "    print(\"Pooled Output Size: \", output[1].shape)\n",
    "    print(\"\\nOutput Encodings: \", output[0])\n",
    "    print(\"\\nOutput Pooled Vector: \", output[1])\n",
    "\n",
    "def print_output_whole(model, text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to('cuda')\n",
    "    output = model(encoded_input['input_ids'], encoded_input['token_type_ids'], encoded_input['attention_mask'])\n",
    "    print(\"Text: \", text)\n",
    "    print(\"Encoded Input Length: \", len(encoded_input['input_ids'][0]))\n",
    "    print(\"Encoded Input: \", encoded_input['input_ids'][0])\n",
    "    print(\"Output Size: \", output.shape)\n",
    "    print(\"Output: \", output)\n",
    "    \"\"\"\n",
    "    print(\"Output Size: \", output[0].shape)\n",
    "    print(\"Pooled Output Size: \", output[1].shape)\n",
    "    print(\"\\nOutput Encodings: \", output[0])\n",
    "    print(\"\\nOutput Pooled Vector: \", output[1])\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "embeddings.position_ids \t torch.Size([1, 512])\n",
      "embeddings.word_embeddings.weight \t torch.Size([30522, 768])\n",
      "embeddings.position_embeddings.weight \t torch.Size([512, 768])\n",
      "embeddings.token_type_embeddings.weight \t torch.Size([2, 768])\n",
      "embeddings.LayerNorm.weight \t torch.Size([768])\n",
      "embeddings.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.0.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.0.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.0.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.0.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.0.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.0.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.0.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.0.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.0.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.0.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.0.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.0.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.0.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.1.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.1.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.1.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.1.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.1.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.1.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.1.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.1.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.1.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.1.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.1.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.1.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.1.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.2.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.2.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.2.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.2.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.2.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.2.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.2.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.2.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.2.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.2.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.2.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.2.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.2.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.3.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.3.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.3.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.3.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.3.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.3.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.3.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.3.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.3.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.3.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.3.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.3.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.3.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.4.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.4.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.4.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.4.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.4.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.4.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.4.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.4.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.4.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.4.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.4.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.4.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.4.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.5.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.5.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.5.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.5.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.5.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.5.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.5.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.5.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.5.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.5.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.5.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.5.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.5.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.6.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.6.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.6.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.6.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.6.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.6.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.6.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.6.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.6.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.6.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.6.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.6.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.6.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.7.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.7.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.7.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.7.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.7.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.7.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.7.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.7.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.7.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.7.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.7.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.7.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.7.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.8.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.8.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.8.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.8.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.8.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.8.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.8.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.8.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.8.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.8.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.8.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.8.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.8.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.9.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.9.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.9.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.9.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.9.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.9.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.9.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.9.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.9.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.9.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.9.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.9.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.9.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.10.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.10.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.10.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.10.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.10.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.10.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.10.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.10.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.10.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.10.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.10.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.10.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.10.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.11.attention.self.query.weight \t torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.query.bias \t torch.Size([768])\n",
      "encoder.layer.11.attention.self.key.weight \t torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.key.bias \t torch.Size([768])\n",
      "encoder.layer.11.attention.self.value.weight \t torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.value.bias \t torch.Size([768])\n",
      "encoder.layer.11.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "encoder.layer.11.attention.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.11.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.11.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "encoder.layer.11.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "encoder.layer.11.intermediate.dense.bias \t torch.Size([3072])\n",
      "encoder.layer.11.output.dense.weight \t torch.Size([768, 3072])\n",
      "encoder.layer.11.output.dense.bias \t torch.Size([768])\n",
      "encoder.layer.11.output.LayerNorm.weight \t torch.Size([768])\n",
      "encoder.layer.11.output.LayerNorm.bias \t torch.Size([768])\n",
      "pooler.dense.weight \t torch.Size([768, 768])\n",
      "pooler.dense.bias \t torch.Size([768])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = print_layers_and_return_weights(model.base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0013, -0.0381, -0.0158,  ...,  0.0244, -0.0008,  0.0240],\n",
       "        [ 0.0020,  0.0151,  0.0033,  ...,  0.0180, -0.0023,  0.0231],\n",
       "        [-0.0386,  0.0145,  0.0621,  ...,  0.0374, -0.0105, -0.0395],\n",
       "        ...,\n",
       "        [-0.0111,  0.0136,  0.0541,  ...,  0.0666,  0.0017, -0.0090],\n",
       "        [ 0.0001,  0.0024, -0.0125,  ...,  0.0046, -0.0014, -0.0079],\n",
       "        [ 0.0415,  0.0751,  0.0305,  ...,  0.0317,  0.0479,  0.0080]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['pooler.dense.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "base_model.embeddings.position_ids \t torch.Size([1, 512])\n",
      "base_model.embeddings.word_embeddings.weight \t torch.Size([30522, 768])\n",
      "base_model.embeddings.position_embeddings.weight \t torch.Size([512, 768])\n",
      "base_model.embeddings.token_type_embeddings.weight \t torch.Size([2, 768])\n",
      "base_model.embeddings.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.embeddings.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.0.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.0.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.0.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.0.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.0.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.0.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.0.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.0.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.1.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.1.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.1.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.1.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.1.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.1.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.1.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.1.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.2.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.2.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.2.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.2.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.2.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.2.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.2.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.2.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.3.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.3.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.3.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.3.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.3.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.3.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.3.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.3.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.4.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.4.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.4.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.4.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.4.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.4.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.4.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.4.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.5.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.5.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.5.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.5.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.5.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.5.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.5.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.5.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.6.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.6.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.6.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.6.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.6.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.6.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.6.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.6.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.6.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.6.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.6.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.6.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.6.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.6.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.6.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.6.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.7.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.7.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.7.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.7.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.7.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.7.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.7.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.7.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.7.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.7.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.7.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.7.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.7.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.7.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.7.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.7.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.8.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.8.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.8.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.8.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.8.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.8.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.8.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.8.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.8.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.8.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.8.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.8.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.8.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.8.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.8.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.8.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.9.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.9.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.9.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.9.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.9.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.9.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.9.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.9.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.9.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.9.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.9.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.9.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.9.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.9.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.9.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.9.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.10.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.10.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.10.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.10.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.10.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.10.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.10.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.10.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.10.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.10.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.10.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.10.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.10.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.10.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.10.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.10.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.11.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.11.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.11.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.11.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.11.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.11.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.11.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.11.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.11.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.11.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.11.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.11.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.11.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.11.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.11.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.11.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.pooler.dense.weight \t torch.Size([768, 768])\n",
      "base_model.pooler.dense.bias \t torch.Size([768])\n",
      "linear.weight \t torch.Size([3, 768])\n",
      "linear.bias \t torch.Size([3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_whole = print_layers_and_return_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0013, -0.0381, -0.0158,  ...,  0.0244, -0.0008,  0.0240],\n",
       "        [ 0.0020,  0.0151,  0.0033,  ...,  0.0180, -0.0023,  0.0231],\n",
       "        [-0.0386,  0.0145,  0.0621,  ...,  0.0374, -0.0105, -0.0395],\n",
       "        ...,\n",
       "        [-0.0111,  0.0136,  0.0541,  ...,  0.0666,  0.0017, -0.0090],\n",
       "        [ 0.0001,  0.0024, -0.0125,  ...,  0.0046, -0.0014, -0.0079],\n",
       "        [ 0.0415,  0.0751,  0.0305,  ...,  0.0317,  0.0479,  0.0080]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_whole['base_model.pooler.dense.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  hello\n",
      "Encoded Input Length:  3\n",
      "Encoded Input:  tensor([ 101, 7592,  102], device='cuda:0')\n",
      "Output Size:  torch.Size([1, 3, 768])\n",
      "Pooled Output Size:  torch.Size([1, 768])\n",
      "\n",
      "Output Encodings:  tensor([[[-0.4145,  0.1708, -0.0262,  ..., -0.3718,  0.2444,  0.2653],\n",
      "         [-0.4951,  0.1428,  0.8051,  ..., -0.4704, -0.4935, -0.1657],\n",
      "         [ 0.7239, -0.0396, -0.2727,  ...,  0.1140, -0.5539, -0.4134]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "Output Pooled Vector:  tensor([[-0.7012, -0.2238,  0.2767,  0.5913, -0.0885, -0.2030,  0.6863,  0.1025,\n",
      "          0.3087, -0.9987,  0.1711,  0.4516,  0.9699, -0.3612,  0.8789, -0.2883,\n",
      "         -0.2684, -0.5411,  0.3246, -0.3785,  0.4412,  0.9559,  0.5557,  0.1000,\n",
      "          0.3645,  0.6114, -0.5838,  0.8944,  0.9231,  0.6767, -0.6094,  0.0210,\n",
      "         -0.9818, -0.1986, -0.1888, -0.9822,  0.0713, -0.6321, -0.0322, -0.0437,\n",
      "         -0.8495,  0.1549,  0.9900, -0.4144,  0.1890, -0.2826, -0.9996,  0.2433,\n",
      "         -0.8600, -0.2694, -0.2285, -0.2372,  0.0485,  0.2888,  0.3312,  0.2792,\n",
      "         -0.0381,  0.1472, -0.1731, -0.4715, -0.4842,  0.3838, -0.0436, -0.8519,\n",
      "         -0.1864, -0.2741, -0.1537, -0.1426, -0.0438, -0.1182,  0.7434,  0.1868,\n",
      "          0.5310, -0.7868, -0.5655,  0.1828, -0.5066,  1.0000, -0.3475, -0.9700,\n",
      "          0.1158, -0.3476,  0.3417,  0.6301, -0.6222, -1.0000,  0.4207, -0.0446,\n",
      "         -0.9819,  0.1101,  0.3040, -0.1651, -0.5157,  0.2612, -0.1875, -0.0326,\n",
      "         -0.1262, -0.0769, -0.2541, -0.0606,  0.1900, -0.2234, -0.1162, -0.4005,\n",
      "          0.0755, -0.3208, -0.3993, -0.1747, -0.4998,  0.4947,  0.3282, -0.1352,\n",
      "          0.1737, -0.9386,  0.4418, -0.1103, -0.9795, -0.3654, -0.9808,  0.5766,\n",
      "         -0.2300, -0.2587,  0.9356,  0.5575,  0.2965,  0.0234,  0.1203, -1.0000,\n",
      "         -0.2172, -0.2347,  0.2027, -0.1403, -0.9650, -0.9549,  0.4028,  0.8980,\n",
      "          0.0323,  0.9852, -0.0777,  0.9255,  0.3619, -0.1984, -0.2618, -0.3519,\n",
      "          0.3916,  0.2899, -0.5165,  0.1720,  0.1909,  0.1600, -0.1383, -0.1082,\n",
      "          0.3352, -0.8832, -0.3638,  0.8863,  0.2442,  0.2581,  0.6218, -0.0613,\n",
      "         -0.4249,  0.8442,  0.3273,  0.2930,  0.1704,  0.4385, -0.3392,  0.3257,\n",
      "         -0.8242,  0.1855,  0.2273, -0.2080,  0.2542, -0.9642, -0.1962,  0.2925,\n",
      "          0.9805,  0.6699,  0.2059, -0.1037, -0.1972,  0.3563, -0.9407,  0.9598,\n",
      "         -0.2211,  0.2335,  0.5401, -0.0832, -0.7526, -0.4977,  0.7108, -0.0159,\n",
      "         -0.8112,  0.0634, -0.3996, -0.2248, -0.0652,  0.4920, -0.2357, -0.2272,\n",
      "          0.0446,  0.8577,  0.8346,  0.5334, -0.4477,  0.5014, -0.8594, -0.3797,\n",
      "          0.0484,  0.3009,  0.1921,  0.9875, -0.2825,  0.0507, -0.8688, -0.9790,\n",
      "          0.0182, -0.8441,  0.0065, -0.5661,  0.3157,  0.3630, -0.3030,  0.3423,\n",
      "         -0.9537, -0.6347,  0.0301, -0.2349,  0.3775, -0.1181,  0.5345,  0.0323,\n",
      "         -0.3746,  0.5239,  0.9232,  0.2057, -0.7189,  0.7024, -0.1874,  0.8039,\n",
      "         -0.4694,  0.8712,  0.3711,  0.6634, -0.8647,  0.0123, -0.7012,  0.1271,\n",
      "         -0.0854, -0.7540, -0.2456,  0.2359,  0.1022,  0.7850, -0.3909,  0.9810,\n",
      "         -0.6263, -0.9321, -0.2684,  0.0039, -0.9813,  0.1400,  0.2120, -0.3591,\n",
      "         -0.3722, -0.1967, -0.9351,  0.7128,  0.0545,  0.9196,  0.1369, -0.8699,\n",
      "         -0.1553, -0.9093, -0.1431, -0.2421,  0.5972, -0.1828, -0.9243,  0.3129,\n",
      "          0.3335,  0.3168,  0.5331,  0.9837,  0.9991,  0.9451,  0.8284,  0.8061,\n",
      "         -0.8931, -0.3872,  0.9991, -0.7126, -0.9999, -0.8701, -0.5161,  0.2024,\n",
      "         -1.0000, -0.0894,  0.0540, -0.8521, -0.3513,  0.9580,  0.9402, -1.0000,\n",
      "          0.4541,  0.8632, -0.4380,  0.3729, -0.2692,  0.9601,  0.3330,  0.3698,\n",
      "         -0.1857,  0.2375, -0.0017, -0.7037,  0.2563,  0.1207,  0.6035, -0.0297,\n",
      "         -0.5537, -0.8631,  0.1463, -0.2220, -0.2035, -0.9484, -0.0728,  0.1106,\n",
      "          0.4972, -0.0028,  0.2111, -0.4788,  0.0799, -0.6224,  0.1893,  0.4670,\n",
      "         -0.8707, -0.0790,  0.4002, -0.6542,  0.4044, -0.9313,  0.9357, -0.2579,\n",
      "          0.0046,  1.0000, -0.0689, -0.7752,  0.3596,  0.0088,  0.2265,  1.0000,\n",
      "          0.3355, -0.9707, -0.4213,  0.0855, -0.2760, -0.3544,  0.9919, -0.0846,\n",
      "          0.2208,  0.4575,  0.9687, -0.9832,  0.4949, -0.8619, -0.9544,  0.9599,\n",
      "          0.9077, -0.2057, -0.1909,  0.1542,  0.2784,  0.1770, -0.9042,  0.5238,\n",
      "          0.4549, -0.1255,  0.8332, -0.6990, -0.1934,  0.1954,  0.0013,  0.4130,\n",
      "          0.1821,  0.4387, -0.1942, -0.0208, -0.3036, -0.2030, -0.9492,  0.2296,\n",
      "          1.0000, -0.0527, -0.0603,  0.0727, -0.0881, -0.3294,  0.1501,  0.2282,\n",
      "         -0.1915, -0.6809, -0.0019, -0.8929, -0.9793,  0.5751,  0.1984, -0.4224,\n",
      "          0.9970,  0.4258,  0.0992,  0.0521,  0.3735,  0.0626,  0.5130, -0.4280,\n",
      "          0.9602, -0.2186,  0.3258,  0.6511,  0.3668, -0.4079, -0.4268, -0.0726,\n",
      "         -0.8577,  0.0864, -0.9207,  0.9108, -0.0948,  0.2224,  0.1604,  0.1125,\n",
      "          1.0000, -0.1386,  0.4644, -0.1346,  0.8341, -0.8707, -0.6824, -0.2621,\n",
      "         -0.0167,  0.4296, -0.0990,  0.1734, -0.9398, -0.4354,  0.0477, -0.9622,\n",
      "         -0.9806,  0.3643,  0.5139, -0.0263, -0.4376, -0.6758, -0.5454, -0.0466,\n",
      "         -0.0560, -0.9193,  0.5907, -0.1213,  0.3928, -0.0874,  0.3852, -0.3361,\n",
      "          0.7948,  0.4103, -0.0379, -0.0910, -0.7183,  0.6182, -0.6565,  0.1816,\n",
      "         -0.0798,  1.0000, -0.4143, -0.0990,  0.5928,  0.4855,  0.0406,  0.1819,\n",
      "          0.1373,  0.3177,  0.4390,  0.5225, -0.5253, -0.2484,  0.4177, -0.4546,\n",
      "         -0.3903,  0.6709,  0.3151, -0.0288,  0.0562,  0.0825,  0.9910, -0.2509,\n",
      "         -0.0177, -0.3802, -0.0520, -0.3481, -0.3276,  1.0000,  0.1425, -0.3331,\n",
      "         -0.9885, -0.0822, -0.8400,  0.9964,  0.6935, -0.3797,  0.4942,  0.3623,\n",
      "         -0.1368,  0.6000, -0.0925, -0.2465,  0.2057,  0.1808,  0.9202, -0.4411,\n",
      "         -0.9516, -0.5104,  0.2529, -0.8901,  0.9369, -0.2539, -0.1298, -0.3642,\n",
      "          0.1940,  0.3453, -0.1369, -0.9647, -0.1936,  0.0834,  0.9465,  0.2170,\n",
      "         -0.3802, -0.8290, -0.1632,  0.1085,  0.1872, -0.9143,  0.9607, -0.9491,\n",
      "          0.4671,  0.9999,  0.2110, -0.7187,  0.0681, -0.3072,  0.0566, -0.1331,\n",
      "          0.3874, -0.9310, -0.1305, -0.2155,  0.1810,  0.0275,  0.0352,  0.5424,\n",
      "          0.1530, -0.2943, -0.4559, -0.0229,  0.2125,  0.4626, -0.3374, -0.0891,\n",
      "          0.1769, -0.1445, -0.8241, -0.1371, -0.2633, -0.9822,  0.4323, -1.0000,\n",
      "         -0.1341, -0.5611, -0.2308,  0.7762,  0.0235, -0.1470, -0.7274,  0.5858,\n",
      "          0.8685,  0.6761, -0.2279,  0.1998, -0.6692,  0.0790, -0.1515,  0.1380,\n",
      "          0.1516,  0.6894, -0.1198,  1.0000,  0.0210, -0.3953, -0.9158,  0.1282,\n",
      "         -0.1406,  0.9991, -0.7056, -0.9480,  0.3609, -0.3532, -0.7511,  0.2639,\n",
      "          0.1610, -0.6737, -0.2456,  0.8578,  0.7050, -0.3607,  0.3929, -0.2642,\n",
      "         -0.2691,  0.1253, -0.3822,  0.9789,  0.1305,  0.7364,  0.2894, -0.0956,\n",
      "          0.9450,  0.2886,  0.3497, -0.0292,  1.0000,  0.2370, -0.8899,  0.3523,\n",
      "         -0.9451, -0.2050, -0.9273,  0.1948,  0.1130,  0.7942, -0.2600,  0.9238,\n",
      "          0.4701,  0.0318, -0.0358,  0.6148,  0.4270, -0.8573, -0.9628, -0.9793,\n",
      "          0.1805, -0.3495, -0.0047,  0.2383,  0.1536,  0.2083,  0.2538, -0.9999,\n",
      "          0.8855,  0.2918, -0.1833,  0.9583,  0.2613,  0.2914,  0.1422, -0.9704,\n",
      "         -0.9102, -0.2208, -0.3017,  0.6754,  0.2617,  0.8566,  0.4065, -0.3386,\n",
      "          0.1654,  0.4698, -0.4067, -0.9898,  0.4241,  0.4106, -0.9080,  0.9409,\n",
      "         -0.5995, -0.2082,  0.6365,  0.0818,  0.7312,  0.3985,  0.5469, -0.0037,\n",
      "          0.4815,  0.8479,  0.8823,  0.9818,  0.3265,  0.5702,  0.3825,  0.2149,\n",
      "          0.6576, -0.8887,  0.0259,  0.0317, -0.2225,  0.3188, -0.0982, -0.8698,\n",
      "          0.3679, -0.2977,  0.5463, -0.3412,  0.1224, -0.3433, -0.0717, -0.4857,\n",
      "         -0.5187,  0.4121,  0.3117,  0.8553,  0.2555, -0.0071, -0.3176, -0.1128,\n",
      "          0.3164, -0.8911,  0.7038,  0.0123,  0.5128, -0.2454, -0.1489,  0.4772,\n",
      "         -0.4437, -0.3139, -0.1535, -0.5406,  0.6796, -0.0638, -0.1931, -0.3637,\n",
      "          0.3048,  0.1867,  0.9663,  0.2022,  0.3431,  0.0622, -0.2355,  0.1852,\n",
      "         -0.2072, -0.9999,  0.2383,  0.1824, -0.1580, -0.0434, -0.1932,  0.1110,\n",
      "         -0.9043, -0.1146, -0.1463, -0.1555, -0.4763, -0.2769,  0.3051,  0.5928,\n",
      "          0.3896,  0.8162,  0.4158,  0.7019,  0.3816,  0.4133, -0.5978,  0.8595]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print_output_innerbert(model.base_model, \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  hello\n",
      "Encoded Input Length:  3\n",
      "Encoded Input:  tensor([ 101, 7592,  102], device='cuda:0')\n",
      "Output Size:  torch.Size([1, 3])\n",
      "Output:  tensor([[ 0.3366,  0.0753, -0.4751]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print_output_whole(model, \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\"hello Ramon\", return_tensors='pt').to('cuda')\n",
    "output = model.base_model(encoded_input['input_ids'],encoded_input['token_type_ids'], encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7592, 12716,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
